{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import os, sys\n",
    "# Packages\n",
    "from model import build_graph, config\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from aae import Operation\n",
    "import dataset\n",
    "from process import Process\n",
    "import sampler\n",
    "import plot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(run_load_from_file=False):\n",
    "    # config\n",
    "    opt = Operation()\n",
    "    opt.check_dir(config.ckpt_dir, is_restart=False)\n",
    "    opt.check_dir(config.log_dir, is_restart=True)\n",
    "\n",
    "    max_epoch = 510\n",
    "    num_trains_per_epoch = 500\n",
    "    batch_size_l = 100\n",
    "    batch_size_u = 100\n",
    "\n",
    "    # create semi-supervised split\n",
    "    # Load minist images\n",
    "    images, labels = dataset.load_train_images()\n",
    "    num_labeled_data = 10000\n",
    "    num_types_of_label = 11  # additional label corresponds to unlabeled data\n",
    "    training_images_l, training_labels_l, training_images_u, _, _ = dataset.create_semisupervised(images, labels, 0, num_labeled_data, num_types_of_label)\n",
    "\n",
    "    # training\n",
    "    with tf.device(config.device):\n",
    "        h = build_graph()\n",
    "\n",
    "    sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "    sess_config.gpu_options.allow_growth = True\n",
    "    sess_config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "    with tf.Session(config=sess_config) as sess:\n",
    "        '''\n",
    "         Load from checkpoint or start a new session\n",
    "\n",
    "        '''\n",
    "        if run_load_from_file:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(config.ckpt_dir))\n",
    "            training_epoch_loss = pickle.load(open(config.ckpt_dir + '/pickle.pkl', 'rb'))\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            training_epoch_loss = []\n",
    "\n",
    "        # Recording loss per epoch\n",
    "        process = Process()\n",
    "        for epoch in range(max_epoch):\n",
    "            process.start_epoch(epoch, max_epoch)\n",
    "\n",
    "            '''\n",
    "            Learning rate generator\n",
    "\n",
    "            '''\n",
    "            learning_rate = opt.ladder_learning_rate(epoch + len(training_epoch_loss))\n",
    "\n",
    "            # Recording loss per iteration\n",
    "            sum_loss_reconstruction = 0\n",
    "            sum_loss_discrminator = 0\n",
    "            sum_loss_generator = 0\n",
    "            process_iteration = Process()\n",
    "            for i in range(num_trains_per_epoch):\n",
    "                process_iteration.start_epoch(i, num_trains_per_epoch)\n",
    "                # Inputs\n",
    "                '''\n",
    "                _l -> labeled\n",
    "                _u -> unlabeled\n",
    "\n",
    "                '''\n",
    "                images_l, label_onehot_l, label_id_l = dataset.sample_labeled_data(training_images_l, training_labels_l, batch_size_l, ndim_y=num_types_of_label)\n",
    "                images_u = dataset.sample_unlabeled_data(training_images_u, batch_size_u)\n",
    "                onehot = np.zeros((1, num_types_of_label), dtype=np.float32)\n",
    "                onehot[-1] = 1\n",
    "                label_onehot_u = np.repeat(onehot, batch_size_u, axis=0)\n",
    "                z_true_l = sampler.supervised_swiss_roll(batch_size_l, config.ndim_z, label_id_l, num_types_of_label - 1)\n",
    "                z_true_u = sampler.swiss_roll(batch_size_u, config.ndim_z, num_types_of_label - 1)\n",
    "                # z_true_l = sampler.supervised_gaussian_mixture(batch_size_l, config.ndim_z, label_id_l, num_types_of_label - 1)\n",
    "                # z_true_u = sampler.gaussian_mixture(batch_size_u, config.ndim_z, num_types_of_label - 1)\n",
    "\n",
    "                # reconstruction_phase\n",
    "                _, loss_reconstruction = sess.run([h.opt_r, h.loss_r], feed_dict={\n",
    "                    h.x: images_u,\n",
    "                    h.lr: learning_rate\n",
    "                })\n",
    "\n",
    "                # adversarial phase for discriminator\n",
    "                _, loss_discriminator_l = sess.run([h.opt_d, h.loss_d], feed_dict={\n",
    "                    h.x: images_l,\n",
    "                    h.label: label_onehot_l,\n",
    "                    h.z: z_true_l,\n",
    "                    h.lr: learning_rate\n",
    "                })\n",
    "\n",
    "                _, loss_discriminator_u = sess.run([h.opt_d, h.loss_d], feed_dict={\n",
    "                    h.x: images_u,\n",
    "                    h.label: label_onehot_u,\n",
    "                    h.z: z_true_u,\n",
    "                    h.lr: learning_rate\n",
    "                })\n",
    "\n",
    "                loss_discriminator = loss_discriminator_l + loss_discriminator_u\n",
    "\n",
    "                # adversarial phase for generator\n",
    "                _, loss_generator_l= sess.run([h.opt_e, h.loss_e,], feed_dict={\n",
    "                    h.x: images_l,\n",
    "                    h.label: label_onehot_l,\n",
    "                    h.lr: learning_rate\n",
    "                })\n",
    "\n",
    "                _, loss_generator_u = sess.run([h.opt_e, h.loss_e], feed_dict={\n",
    "                    h.x: images_u,\n",
    "                    h.label: label_onehot_u,\n",
    "                    h.lr: learning_rate\n",
    "                })\n",
    "                loss_generator = loss_generator_l + loss_generator_u\n",
    "\n",
    "                sum_loss_reconstruction += loss_reconstruction / batch_size_u\n",
    "                sum_loss_discrminator += loss_discriminator\n",
    "                sum_loss_generator += loss_generator\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    process_iteration.show_table_2d(i, num_trains_per_epoch, {\n",
    "                        'reconstruction': sum_loss_reconstruction / (i + 1),\n",
    "                        'discriminator': sum_loss_discrminator / (i + 1),\n",
    "                        'generator': sum_loss_generator / (i + 1),\n",
    "                    })\n",
    "\n",
    "            average_loss_per_epoch = [\n",
    "                sum_loss_reconstruction / num_trains_per_epoch,\n",
    "                sum_loss_discrminator / num_trains_per_epoch,\n",
    "                sum_loss_generator / num_trains_per_epoch,\n",
    "            ]\n",
    "            training_epoch_loss.append(average_loss_per_epoch)\n",
    "            training_loss_name = [\n",
    "                'reconstruction',\n",
    "                'discriminator',\n",
    "                'generator'\n",
    "            ]\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                process.show_bar(epoch, max_epoch, {\n",
    "                    'loss_r': average_loss_per_epoch[0],\n",
    "                    'loss_d': average_loss_per_epoch[1],\n",
    "                    'loss_g': average_loss_per_epoch[2]\n",
    "                })\n",
    "\n",
    "                plt.tile_images(sess.run(h.x_, feed_dict={h.x: images_u}),\n",
    "                                dir=config.log_dir,\n",
    "                                filename='x_rec_epoch_{}'.format(str(epoch).zfill(3)))\n",
    "\n",
    "                plt.scatter_labeled_z(sess.run(h.z_r, feed_dict={h.x: images[:1000]}), [int(var) for var in labels[:1000]],\n",
    "                                      dir=config.log_dir,\n",
    "                                      filename='z_representation-{}'.format(epoch))\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                saver.save(sess, os.path.join(config.ckpt_dir, 'model_ckptpoint'), global_step=epoch)\n",
    "                pickle.dump((training_epoch_loss, training_loss_name), open(config.ckpt_dir + '/pickle.pkl', 'wb'))\n",
    "                plt.plot_double_scale_trend(config.ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:04:52\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.98221     |     1.73840     |     3.67254    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch:  0/510[...................................................................................................]--02:45:22-- - loss_d: 2.73370 -  - loss_g: 1.36089 -  - loss_r: 1.02237 - \n",
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:00:20\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.71275     |     1.31924     |     0.90188    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch:  1/510[...................................................................................................]--02:46:20-- - loss_d: 2.74307 -  - loss_g: 1.34428 -  - loss_r: 0.91682 - \n",
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:00:20\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.81764     |     1.33471     |     0.92872    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch:  2/510[...................................................................................................]--02:46:19-- - loss_d: 2.73750 -  - loss_g: 1.37423 -  - loss_r: 0.90901 - \n",
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:00:20\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.66118     |     1.40820     |     0.91260    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch:  3/510[...................................................................................................]--02:43:40-- - loss_d: 2.73887 -  - loss_g: 1.38701 -  - loss_r: 0.90401 - \n",
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:00:21\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.75722     |     1.44041     |     0.90789    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch:  4/510[...................................................................................................]--02:45:43-- - loss_d: 2.74072 -  - loss_g: 1.40152 -  - loss_r: 0.89422 - \n",
      "\n",
      "Iteration:  0(500 in total)\t Time left:00:00:19\n",
      "-----------------------------------------------------\n",
      " discriminator  |    generator    | reconstruction \n",
      "-----------------------------------------------------\n",
      "    2.65809     |     1.47398     |     0.88590    \n",
      "-----------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f4c655d17e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_load_from_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ba3516459c33>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(run_load_from_file)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 '''\n\u001b[1;32m     64\u001b[0m                 \u001b[0mimages_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_onehot_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_id_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_labeled_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_images_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_types_of_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mimages_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_unlabeled_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_images_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0monehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_types_of_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0monehot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\CYD\\Desktop\\AAE_advanced\\dataset.py\u001b[0m in \u001b[0;36msample_unlabeled_data\u001b[0;34m(images, batch_size, ndim_x)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mdata_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mimage_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.reset_default_graph()\n",
    "    main(run_load_from_file=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
